{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. TensorFlow Estimators\n",
    "## Basic imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "\n",
    "tf.random.set_seed(1)\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load the data and apply the necessary preprocessing steps\n",
    "- Preprocessing involves partitioning the dataset into training and testing datasets, as well as standardizing the continuous features\n",
    "### 1. Download and import the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "      MPG  Cylinders  Displacement  Horsepower  Weight  Acceleration  \\\n393  27.0          4         140.0        86.0  2790.0          15.6   \n394  44.0          4          97.0        52.0  2130.0          24.6   \n395  32.0          4         135.0        84.0  2295.0          11.6   \n396  28.0          4         120.0        79.0  2625.0          18.6   \n397  31.0          4         119.0        82.0  2720.0          19.4   \n\n     ModelYear  Origin  \n393         82       1  \n394         82       2  \n395         82       1  \n396         82       1  \n397         82       1  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>MPG</th>\n      <th>Cylinders</th>\n      <th>Displacement</th>\n      <th>Horsepower</th>\n      <th>Weight</th>\n      <th>Acceleration</th>\n      <th>ModelYear</th>\n      <th>Origin</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>393</th>\n      <td>27.0</td>\n      <td>4</td>\n      <td>140.0</td>\n      <td>86.0</td>\n      <td>2790.0</td>\n      <td>15.6</td>\n      <td>82</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>394</th>\n      <td>44.0</td>\n      <td>4</td>\n      <td>97.0</td>\n      <td>52.0</td>\n      <td>2130.0</td>\n      <td>24.6</td>\n      <td>82</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>395</th>\n      <td>32.0</td>\n      <td>4</td>\n      <td>135.0</td>\n      <td>84.0</td>\n      <td>2295.0</td>\n      <td>11.6</td>\n      <td>82</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>396</th>\n      <td>28.0</td>\n      <td>4</td>\n      <td>120.0</td>\n      <td>79.0</td>\n      <td>2625.0</td>\n      <td>18.6</td>\n      <td>82</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>397</th>\n      <td>31.0</td>\n      <td>4</td>\n      <td>119.0</td>\n      <td>82.0</td>\n      <td>2720.0</td>\n      <td>19.4</td>\n      <td>82</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "dataset_path = tf.keras.utils.get_file(\"auto-mpg.data\", \n",
    "                                       (\"http://archive.ics.uci.edu/ml/machine-learning-databases\"\n",
    "                                        \"/auto-mpg/auto-mpg.data\"))\n",
    "\n",
    "column_names = ['MPG', 'Cylinders', 'Displacement', 'Horsepower',\n",
    "                'Weight', 'Acceleration', 'ModelYear', 'Origin']\n",
    "\n",
    "df = pd.read_csv(dataset_path, names=column_names,\n",
    "                 na_values = \"?\", comment='\\t',\n",
    "                 sep=\" \", skipinitialspace=True)\n",
    "\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Drop rows that contain empty values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "MPG             0\nCylinders       0\nDisplacement    0\nHorsepower      6\nWeight          0\nAcceleration    0\nModelYear       0\nOrigin          0\ndtype: int64\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "      MPG  Cylinders  Displacement  Horsepower  Weight  Acceleration  \\\n387  27.0          4         140.0        86.0  2790.0          15.6   \n388  44.0          4          97.0        52.0  2130.0          24.6   \n389  32.0          4         135.0        84.0  2295.0          11.6   \n390  28.0          4         120.0        79.0  2625.0          18.6   \n391  31.0          4         119.0        82.0  2720.0          19.4   \n\n     ModelYear  Origin  \n387         82       1  \n388         82       2  \n389         82       1  \n390         82       1  \n391         82       1  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>MPG</th>\n      <th>Cylinders</th>\n      <th>Displacement</th>\n      <th>Horsepower</th>\n      <th>Weight</th>\n      <th>Acceleration</th>\n      <th>ModelYear</th>\n      <th>Origin</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>387</th>\n      <td>27.0</td>\n      <td>4</td>\n      <td>140.0</td>\n      <td>86.0</td>\n      <td>2790.0</td>\n      <td>15.6</td>\n      <td>82</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>388</th>\n      <td>44.0</td>\n      <td>4</td>\n      <td>97.0</td>\n      <td>52.0</td>\n      <td>2130.0</td>\n      <td>24.6</td>\n      <td>82</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>389</th>\n      <td>32.0</td>\n      <td>4</td>\n      <td>135.0</td>\n      <td>84.0</td>\n      <td>2295.0</td>\n      <td>11.6</td>\n      <td>82</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>390</th>\n      <td>28.0</td>\n      <td>4</td>\n      <td>120.0</td>\n      <td>79.0</td>\n      <td>2625.0</td>\n      <td>18.6</td>\n      <td>82</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>391</th>\n      <td>31.0</td>\n      <td>4</td>\n      <td>119.0</td>\n      <td>82.0</td>\n      <td>2720.0</td>\n      <td>19.4</td>\n      <td>82</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "print(df.isna().sum())\n",
    "\n",
    "df = df.dropna()\n",
    "df = df.reset_index(drop=True)\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Split the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "              count         mean         std     min     25%     50%     75%  \\\nMPG           313.0    23.404153    7.666909     9.0    17.5    23.0    29.0   \nCylinders     313.0     5.402556    1.701506     3.0     4.0     4.0     8.0   \nDisplacement  313.0   189.512780  102.675646    68.0   104.0   140.0   260.0   \nHorsepower    313.0   102.929712   37.919046    46.0    75.0    92.0   120.0   \nWeight        313.0  2961.198083  848.602146  1613.0  2219.0  2755.0  3574.0   \nAcceleration  313.0    15.704473    2.725399     8.5    14.0    15.5    17.3   \nModelYear     313.0    75.929712    3.675305    70.0    73.0    76.0    79.0   \nOrigin        313.0     1.591054    0.807923     1.0     1.0     1.0     2.0   \n\n                 max  \nMPG             46.6  \nCylinders        8.0  \nDisplacement   455.0  \nHorsepower     230.0  \nWeight        5140.0  \nAcceleration    24.8  \nModelYear       82.0  \nOrigin           3.0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>count</th>\n      <th>mean</th>\n      <th>std</th>\n      <th>min</th>\n      <th>25%</th>\n      <th>50%</th>\n      <th>75%</th>\n      <th>max</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>MPG</th>\n      <td>313.0</td>\n      <td>23.404153</td>\n      <td>7.666909</td>\n      <td>9.0</td>\n      <td>17.5</td>\n      <td>23.0</td>\n      <td>29.0</td>\n      <td>46.6</td>\n    </tr>\n    <tr>\n      <th>Cylinders</th>\n      <td>313.0</td>\n      <td>5.402556</td>\n      <td>1.701506</td>\n      <td>3.0</td>\n      <td>4.0</td>\n      <td>4.0</td>\n      <td>8.0</td>\n      <td>8.0</td>\n    </tr>\n    <tr>\n      <th>Displacement</th>\n      <td>313.0</td>\n      <td>189.512780</td>\n      <td>102.675646</td>\n      <td>68.0</td>\n      <td>104.0</td>\n      <td>140.0</td>\n      <td>260.0</td>\n      <td>455.0</td>\n    </tr>\n    <tr>\n      <th>Horsepower</th>\n      <td>313.0</td>\n      <td>102.929712</td>\n      <td>37.919046</td>\n      <td>46.0</td>\n      <td>75.0</td>\n      <td>92.0</td>\n      <td>120.0</td>\n      <td>230.0</td>\n    </tr>\n    <tr>\n      <th>Weight</th>\n      <td>313.0</td>\n      <td>2961.198083</td>\n      <td>848.602146</td>\n      <td>1613.0</td>\n      <td>2219.0</td>\n      <td>2755.0</td>\n      <td>3574.0</td>\n      <td>5140.0</td>\n    </tr>\n    <tr>\n      <th>Acceleration</th>\n      <td>313.0</td>\n      <td>15.704473</td>\n      <td>2.725399</td>\n      <td>8.5</td>\n      <td>14.0</td>\n      <td>15.5</td>\n      <td>17.3</td>\n      <td>24.8</td>\n    </tr>\n    <tr>\n      <th>ModelYear</th>\n      <td>313.0</td>\n      <td>75.929712</td>\n      <td>3.675305</td>\n      <td>70.0</td>\n      <td>73.0</td>\n      <td>76.0</td>\n      <td>79.0</td>\n      <td>82.0</td>\n    </tr>\n    <tr>\n      <th>Origin</th>\n      <td>313.0</td>\n      <td>1.591054</td>\n      <td>0.807923</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>3.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "import sklearn\n",
    "import sklearn.model_selection\n",
    "\n",
    "df_train, df_test = sklearn.model_selection.train_test_split(df, train_size=0.8)\n",
    "train_stats = df_train.describe().transpose()\n",
    "train_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Standardize the continuous (\"numerical\") features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "      MPG  Cylinders  Displacement  Horsepower    Weight  Acceleration  \\\n203  28.0  -0.824303     -0.901020   -0.736562 -0.950031      0.255202   \n255  19.4   0.351127      0.413800   -0.340982  0.293190      0.548737   \n72   13.0   1.526556      1.144256    0.713897  1.339617     -0.625403   \n235  30.5  -0.824303     -0.891280   -1.053025 -1.072585      0.475353   \n37   14.0   1.526556      1.563051    1.636916  1.470420     -1.359240   \n\n     ModelYear  Origin  \n203         76       3  \n255         78       1  \n72          72       1  \n235         77       1  \n37          71       1  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>MPG</th>\n      <th>Cylinders</th>\n      <th>Displacement</th>\n      <th>Horsepower</th>\n      <th>Weight</th>\n      <th>Acceleration</th>\n      <th>ModelYear</th>\n      <th>Origin</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>203</th>\n      <td>28.0</td>\n      <td>-0.824303</td>\n      <td>-0.901020</td>\n      <td>-0.736562</td>\n      <td>-0.950031</td>\n      <td>0.255202</td>\n      <td>76</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>255</th>\n      <td>19.4</td>\n      <td>0.351127</td>\n      <td>0.413800</td>\n      <td>-0.340982</td>\n      <td>0.293190</td>\n      <td>0.548737</td>\n      <td>78</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>72</th>\n      <td>13.0</td>\n      <td>1.526556</td>\n      <td>1.144256</td>\n      <td>0.713897</td>\n      <td>1.339617</td>\n      <td>-0.625403</td>\n      <td>72</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>235</th>\n      <td>30.5</td>\n      <td>-0.824303</td>\n      <td>-0.891280</td>\n      <td>-1.053025</td>\n      <td>-1.072585</td>\n      <td>0.475353</td>\n      <td>77</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>14.0</td>\n      <td>1.526556</td>\n      <td>1.563051</td>\n      <td>1.636916</td>\n      <td>1.470420</td>\n      <td>-1.359240</td>\n      <td>71</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "numeric_column_names = ['Cylinders', 'Displacement', 'Horsepower', 'Weight', 'Acceleration']\n",
    "\n",
    "df_train_norm, df_test_norm = df_train.copy(), df_test.copy()\n",
    "\n",
    "for col_name in numeric_column_names:\n",
    "    mean = train_stats.loc[col_name, 'mean']\n",
    "    std  = train_stats.loc[col_name, 'std']\n",
    "    df_train_norm.loc[:, col_name] = (df_train_norm.loc[:, col_name] - mean)/std\n",
    "    df_test_norm.loc[:, col_name] = (df_test_norm.loc[:, col_name] - mean)/std\n",
    "    \n",
    "df_train_norm.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Transform the continuous features into the feature column data structure that TensorFlow Estimators can work with\n",
    " * See definition: https://developers.google.com/machine-learning/glossary/#feature_columns\n",
    " * Documentation: https://www.tensorflow.org/api_docs/python/tf/feature_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[NumericColumn(key='Cylinders', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n NumericColumn(key='Displacement', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n NumericColumn(key='Horsepower', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n NumericColumn(key='Weight', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n NumericColumn(key='Acceleration', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)]"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "numeric_features = []\n",
    "\n",
    "for col_name in numeric_column_names:\n",
    "    numeric_features.append(tf.feature_column.numeric_column(key=col_name))\n",
    "    \n",
    "numeric_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Group the model year information into buckets\n",
    "- The chosen intervals for \"bucketing\" are arbitrary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[BucketizedColumn(source_column=NumericColumn(key='ModelYear', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), boundaries=(73, 76, 79))]\n"
    }
   ],
   "source": [
    "feature_year = tf.feature_column.numeric_column(key=\"ModelYear\")\n",
    "\n",
    "bucketized_features = []\n",
    "\n",
    "bucketized_features.append(tf.feature_column.bucketized_column(\n",
    "    source_column=feature_year,\n",
    "    boundaries=[73, 76, 79]))\n",
    "\n",
    "print(bucketized_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Define a list for the unordered categorical feature, Origin\n",
    "- We can use tf.feature_column.categorical_column_with_identity() function if the features are already associated with an index of categories in the range [0, num_categories)\n",
    "- However, in this case we cannot do that since the indices of Origin start from 1 and not from 0 as required, so we proceed with the vocabulary list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "feature_origin = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "    key='Origin',\n",
    "    vocabulary_list=[1, 2, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Convert the existing categorical feature column to a dense column\n",
    "- Certain Estimators oncly accept so-called \"dense columns\"\n",
    "- We can convert an existing categorical feature column to a dense column using an embedding column or an indicator column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='Origin', vocabulary_list=(1, 2, 3), dtype=tf.int32, default_value=-1, num_oov_buckets=0))]\n"
    }
   ],
   "source": [
    "categorical_indicator_features = []\n",
    "categorical_indicator_features.append(tf.feature_column.indicator_column(feature_origin))\n",
    "\n",
    "print(categorical_indicator_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Machine learning with pre-made Estimators\n",
    "### Steps for using pre-made estimators\n",
    "\n",
    " * **Step 1:** Define the input function for importing the data   \n",
    " * **Step 2:**  Define the feature columns to bridge between the estimator and the data   \n",
    " * **Step 3:** Instantiate an estimator or convert a Keras model to an estimator   \n",
    " * **Step 4:** Use the estimator: train() evaluate() predict()\n",
    "\n",
    "### 1. Define the input function for importing the data\n",
    "- For the first step, we need to define a function that processes the data and returns a TensorFlow dataset cosisting of a tuple that contains the input features and the labels (ground truth MPG values)\n",
    "- The features must be in a dictionary format, and the keys of the dictionary must match the feature columns' names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Keys: dict_keys(['Cylinders', 'Displacement', 'Horsepower', 'Weight', 'Acceleration', 'ModelYear', 'Origin'])\nBatch Model Years: tf.Tensor([82 78 76 72 78 73 70 78], shape=(8,), dtype=int32)\n"
    }
   ],
   "source": [
    "def train_input_fn(df_train, batch_size=8):\n",
    "    df = df_train.copy()\n",
    "    train_x, train_y = df, df.pop('MPG')\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((dict(train_x), train_y))\n",
    "\n",
    "    # shuffle, repeat, and batch the examples\n",
    "    return dataset.shuffle(1000).repeat().batch(batch_size)\n",
    "\n",
    "## inspection\n",
    "ds = train_input_fn(df_train_norm)\n",
    "batch = next(iter(ds))\n",
    "print('Keys:', batch[0].keys())\n",
    "print('Batch Model Years:', batch[0]['ModelYear'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Define the feature columns\n",
    "- We have already defined 3 lists for the continuous features, the bucketized feature column, and categorical feature column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[NumericColumn(key='Cylinders', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='Displacement', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='Horsepower', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='Weight', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='Acceleration', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), BucketizedColumn(source_column=NumericColumn(key='ModelYear', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), boundaries=(73, 76, 79)), IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='Origin', vocabulary_list=(1, 2, 3), dtype=tf.int32, default_value=-1, num_oov_buckets=0))]\n"
    }
   ],
   "source": [
    "all_feature_columns = (numeric_features + \n",
    "                       bucketized_features + \n",
    "                       categorical_indicator_features)\n",
    "\n",
    "print(all_feature_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Instantiate an estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "INFO:tensorflow:Using default config.\nINFO:tensorflow:Using config: {'_model_dir': 'models/autompg-dnnregressor/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\ngraph_options {\n  rewrite_options {\n    meta_optimizer_iterations: ONE\n  }\n}\n, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000001CEB40147C8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
    }
   ],
   "source": [
    "regressor = tf.estimator.DNNRegressor(\n",
    "    feature_columns=all_feature_columns,\n",
    "    hidden_units=[32, 10],\n",
    "    model_dir='models/autompg-dnnregressor/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. Finally, train the regressor\n",
    "- The regressor can be trained by calling the train() method, for which we require the previously defined input function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": " = 16.67799, step = 20300 (0.111 sec)\nINFO:tensorflow:global_step/sec: 836.577\nINFO:tensorflow:loss = 14.104445, step = 20400 (0.120 sec)\nINFO:tensorflow:global_step/sec: 907.438\nINFO:tensorflow:loss = 28.777363, step = 20500 (0.110 sec)\nINFO:tensorflow:global_step/sec: 933.412\nINFO:tensorflow:loss = 29.093853, step = 20600 (0.107 sec)\nINFO:tensorflow:global_step/sec: 860.592\nINFO:tensorflow:loss = 15.665294, step = 20700 (0.117 sec)\nINFO:tensorflow:global_step/sec: 697.006\nINFO:tensorflow:loss = 62.035095, step = 20800 (0.142 sec)\nINFO:tensorflow:global_step/sec: 774.869\nINFO:tensorflow:loss = 11.360391, step = 20900 (0.130 sec)\nINFO:tensorflow:global_step/sec: 819.339\nINFO:tensorflow:loss = 49.79663, step = 21000 (0.122 sec)\nINFO:tensorflow:global_step/sec: 800.556\nINFO:tensorflow:loss = 23.985207, step = 21100 (0.125 sec)\nINFO:tensorflow:global_step/sec: 786.984\nINFO:tensorflow:loss = 28.185383, step = 21200 (0.128 sec)\nINFO:tensorflow:global_step/sec: 657.048\nINFO:tensorflow:loss = 22.202744, step = 21300 (0.152 sec)\nINFO:tensorflow:global_step/sec: 692.746\nINFO:tensorflow:loss = 4.1460733, step = 21400 (0.144 sec)\nINFO:tensorflow:global_step/sec: 649.721\nINFO:tensorflow:loss = 8.756647, step = 21500 (0.156 sec)\nINFO:tensorflow:global_step/sec: 530.569\nINFO:tensorflow:loss = 19.145424, step = 21600 (0.188 sec)\nINFO:tensorflow:global_step/sec: 756.985\nINFO:tensorflow:loss = 63.02963, step = 21700 (0.132 sec)\nINFO:tensorflow:global_step/sec: 783.382\nINFO:tensorflow:loss = 15.758701, step = 21800 (0.129 sec)\nINFO:tensorflow:global_step/sec: 869.823\nINFO:tensorflow:loss = 7.905738, step = 21900 (0.111 sec)\nINFO:tensorflow:global_step/sec: 814.085\nINFO:tensorflow:loss = 24.105682, step = 22000 (0.124 sec)\nINFO:tensorflow:global_step/sec: 853.945\nINFO:tensorflow:loss = 26.63905, step = 22100 (0.117 sec)\nINFO:tensorflow:global_step/sec: 959.222\nINFO:tensorflow:loss = 16.057178, step = 22200 (0.104 sec)\nINFO:tensorflow:global_step/sec: 638.473\nINFO:tensorflow:loss = 13.844851, step = 22300 (0.156 sec)\nINFO:tensorflow:global_step/sec: 522.586\nINFO:tensorflow:loss = 25.623276, step = 22400 (0.193 sec)\nINFO:tensorflow:global_step/sec: 736.863\nINFO:tensorflow:loss = 10.84231, step = 22500 (0.135 sec)\nINFO:tensorflow:global_step/sec: 766.604\nINFO:tensorflow:loss = 13.983078, step = 22600 (0.131 sec)\nINFO:tensorflow:global_step/sec: 805.649\nINFO:tensorflow:loss = 58.765373, step = 22700 (0.126 sec)\nINFO:tensorflow:global_step/sec: 737.061\nINFO:tensorflow:loss = 17.720177, step = 22800 (0.137 sec)\nINFO:tensorflow:global_step/sec: 751.774\nINFO:tensorflow:loss = 15.914854, step = 22900 (0.130 sec)\nINFO:tensorflow:global_step/sec: 750.613\nINFO:tensorflow:loss = 41.308155, step = 23000 (0.134 sec)\nINFO:tensorflow:global_step/sec: 721.233\nINFO:tensorflow:loss = 44.300686, step = 23100 (0.139 sec)\nINFO:tensorflow:global_step/sec: 777.513\nINFO:tensorflow:loss = 6.918442, step = 23200 (0.130 sec)\nINFO:tensorflow:global_step/sec: 700.772\nINFO:tensorflow:loss = 22.43306, step = 23300 (0.141 sec)\nINFO:tensorflow:global_step/sec: 752.444\nINFO:tensorflow:loss = 11.774006, step = 23400 (0.133 sec)\nINFO:tensorflow:global_step/sec: 689.655\nINFO:tensorflow:loss = 10.501809, step = 23500 (0.145 sec)\nINFO:tensorflow:global_step/sec: 691.038\nINFO:tensorflow:loss = 57.122097, step = 23600 (0.149 sec)\nINFO:tensorflow:global_step/sec: 686.169\nINFO:tensorflow:loss = 6.978155, step = 23700 (0.142 sec)\nINFO:tensorflow:global_step/sec: 542.208\nINFO:tensorflow:loss = 12.532036, step = 23800 (0.185 sec)\nINFO:tensorflow:global_step/sec: 665.833\nINFO:tensorflow:loss = 8.947853, step = 23900 (0.149 sec)\nINFO:tensorflow:global_step/sec: 735.813\nINFO:tensorflow:loss = 36.34711, step = 24000 (0.139 sec)\nINFO:tensorflow:global_step/sec: 803.507\nINFO:tensorflow:loss = 15.827623, step = 24100 (0.122 sec)\nINFO:tensorflow:global_step/sec: 721.117\nINFO:tensorflow:loss = 13.070802, step = 24200 (0.139 sec)\nINFO:tensorflow:global_step/sec: 741.519\nINFO:tensorflow:loss = 30.580479, step = 24300 (0.134 sec)\nINFO:tensorflow:global_step/sec: 696.081\nINFO:tensorflow:loss = 45.891273, step = 24400 (0.147 sec)\nINFO:tensorflow:global_step/sec: 766.932\nINFO:tensorflow:loss = 33.79174, step = 24500 (0.146 sec)\nINFO:tensorflow:global_step/sec: 861.777\nINFO:tensorflow:loss = 22.36711, step = 24600 (0.097 sec)\nINFO:tensorflow:global_step/sec: 1172.46\nINFO:tensorflow:loss = 11.40797, step = 24700 (0.085 sec)\nINFO:tensorflow:global_step/sec: 1118.68\nINFO:tensorflow:loss = 10.093775, step = 24800 (0.090 sec)\nINFO:tensorflow:global_step/sec: 993.139\nINFO:tensorflow:loss = 4.053932, step = 24900 (0.100 sec)\nINFO:tensorflow:global_step/sec: 816.491\nINFO:tensorflow:loss = 6.1299014, step = 25000 (0.125 sec)\nINFO:tensorflow:global_step/sec: 762.856\nINFO:tensorflow:loss = 9.951902, step = 25100 (0.131 sec)\nINFO:tensorflow:global_step/sec: 764.093\nINFO:tensorflow:loss = 12.259611, step = 25200 (0.131 sec)\nINFO:tensorflow:global_step/sec: 771.066\nINFO:tensorflow:loss = 19.550829, step = 25300 (0.127 sec)\nINFO:tensorflow:global_step/sec: 851.241\nINFO:tensorflow:loss = 6.571498, step = 25400 (0.118 sec)\nINFO:tensorflow:global_step/sec: 1077.49\nINFO:tensorflow:loss = 27.223854, step = 25500 (0.092 sec)\nINFO:tensorflow:global_step/sec: 794.418\nINFO:tensorflow:loss = 5.4769783, step = 25600 (0.127 sec)\nINFO:tensorflow:global_step/sec: 697.795\nINFO:tensorflow:loss = 7.552918, step = 25700 (0.142 sec)\nINFO:tensorflow:global_step/sec: 642.424\nINFO:tensorflow:loss = 6.6473427, step = 25800 (0.158 sec)\nINFO:tensorflow:global_step/sec: 612.886\nINFO:tensorflow:loss = 13.24791, step = 25900 (0.163 sec)\nINFO:tensorflow:global_step/sec: 568.364\nINFO:tensorflow:loss = 8.0499115, step = 26000 (0.177 sec)\nINFO:tensorflow:global_step/sec: 576.798\nINFO:tensorflow:loss = 9.026293, step = 26100 (0.172 sec)\nINFO:tensorflow:global_step/sec: 544.736\nINFO:tensorflow:loss = 15.7674885, step = 26200 (0.183 sec)\nINFO:tensorflow:global_step/sec: 697.611\nINFO:tensorflow:loss = 21.043037, step = 26300 (0.143 sec)\nINFO:tensorflow:global_step/sec: 710.929\nINFO:tensorflow:loss = 5.369046, step = 26400 (0.141 sec)\nINFO:tensorflow:global_step/sec: 722.712\nINFO:tensorflow:loss = 21.179365, step = 26500 (0.142 sec)\nINFO:tensorflow:global_step/sec: 588.518\nINFO:tensorflow:loss = 3.2867556, step = 26600 (0.167 sec)\nINFO:tensorflow:global_step/sec: 634.044\nINFO:tensorflow:loss = 23.796064, step = 26700 (0.159 sec)\nINFO:tensorflow:global_step/sec: 674.99\nINFO:tensorflow:loss = 33.131157, step = 26800 (0.147 sec)\nINFO:tensorflow:global_step/sec: 621.773\nINFO:tensorflow:loss = 7.5029116, step = 26900 (0.161 sec)\nINFO:tensorflow:global_step/sec: 768.928\nINFO:tensorflow:loss = 8.423882, step = 27000 (0.132 sec)\nINFO:tensorflow:global_step/sec: 785.349\nINFO:tensorflow:loss = 39.594875, step = 27100 (0.124 sec)\nINFO:tensorflow:global_step/sec: 736.124\nINFO:tensorflow:loss = 22.470402, step = 27200 (0.137 sec)\nINFO:tensorflow:global_step/sec: 740.111\nINFO:tensorflow:loss = 23.346115, step = 27300 (0.133 sec)\nINFO:tensorflow:global_step/sec: 596.966\nINFO:tensorflow:loss = 9.82083, step = 27400 (0.171 sec)\nINFO:tensorflow:global_step/sec: 644.343\nINFO:tensorflow:loss = 9.604251, step = 27500 (0.153 sec)\nINFO:tensorflow:global_step/sec: 731.514\nINFO:tensorflow:loss = 33.774002, step = 27600 (0.137 sec)\nINFO:tensorflow:global_step/sec: 753.761\nINFO:tensorflow:loss = 28.555523, step = 27700 (0.132 sec)\nINFO:tensorflow:global_step/sec: 672.007\nINFO:tensorflow:loss = 6.073638, step = 27800 (0.150 sec)\nINFO:tensorflow:global_step/sec: 594.713\nINFO:tensorflow:loss = 11.435819, step = 27900 (0.168 sec)\nINFO:tensorflow:global_step/sec: 704.539\nINFO:tensorflow:loss = 15.596548, step = 28000 (0.143 sec)\nINFO:tensorflow:global_step/sec: 657.499\nINFO:tensorflow:loss = 7.9974375, step = 28100 (0.152 sec)\nINFO:tensorflow:global_step/sec: 673.026\nINFO:tensorflow:loss = 11.745723, step = 28200 (0.150 sec)\nINFO:tensorflow:global_step/sec: 704.099\nINFO:tensorflow:loss = 12.081343, step = 28300 (0.140 sec)\nINFO:tensorflow:global_step/sec: 786.887\nINFO:tensorflow:loss = 3.2356591, step = 28400 (0.127 sec)\nINFO:tensorflow:global_step/sec: 782.127\nINFO:tensorflow:loss = 7.4542637, step = 28500 (0.126 sec)\nINFO:tensorflow:global_step/sec: 788.305\nINFO:tensorflow:loss = 21.319965, step = 28600 (0.128 sec)\nINFO:tensorflow:global_step/sec: 757.528\nINFO:tensorflow:loss = 11.997042, step = 28700 (0.132 sec)\nINFO:tensorflow:global_step/sec: 613.669\nINFO:tensorflow:loss = 5.4523296, step = 28800 (0.165 sec)\nINFO:tensorflow:global_step/sec: 629.663\nINFO:tensorflow:loss = 9.888369, step = 28900 (0.157 sec)\nINFO:tensorflow:global_step/sec: 728.838\nINFO:tensorflow:loss = 37.41678, step = 29000 (0.140 sec)\nINFO:tensorflow:global_step/sec: 789.076\nINFO:tensorflow:loss = 26.318073, step = 29100 (0.125 sec)\nINFO:tensorflow:global_step/sec: 776.078\nINFO:tensorflow:loss = 23.114088, step = 29200 (0.128 sec)\nINFO:tensorflow:global_step/sec: 763.643\nINFO:tensorflow:loss = 3.6129909, step = 29300 (0.132 sec)\nINFO:tensorflow:global_step/sec: 849.638\nINFO:tensorflow:loss = 10.32325, step = 29400 (0.118 sec)\nINFO:tensorflow:global_step/sec: 715.134\nINFO:tensorflow:loss = 16.022827, step = 29500 (0.139 sec)\nINFO:tensorflow:global_step/sec: 577.367\nINFO:tensorflow:loss = 13.85598, step = 29600 (0.176 sec)\nWARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 29615 vs previous value: 29615. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\nINFO:tensorflow:global_step/sec: 528.32\nINFO:tensorflow:loss = 19.656807, step = 29700 (0.186 sec)\nINFO:tensorflow:global_step/sec: 633.094\nINFO:tensorflow:loss = 17.290598, step = 29800 (0.160 sec)\nINFO:tensorflow:global_step/sec: 574.966\nINFO:tensorflow:loss = 7.630457, step = 29900 (0.173 sec)\nINFO:tensorflow:global_step/sec: 710.981\nINFO:tensorflow:loss = 6.369185, step = 30000 (0.140 sec)\nINFO:tensorflow:global_step/sec: 832.249\nINFO:tensorflow:loss = 13.078379, step = 30100 (0.121 sec)\nINFO:tensorflow:global_step/sec: 746.19\nINFO:tensorflow:loss = 25.045395, step = 30200 (0.136 sec)\nINFO:tensorflow:global_step/sec: 751.304\nINFO:tensorflow:loss = 24.821152, step = 30300 (0.132 sec)\nINFO:tensorflow:global_step/sec: 761.638\nINFO:tensorflow:loss = 26.78096, step = 30400 (0.129 sec)\nINFO:tensorflow:global_step/sec: 775.399\nINFO:tensorflow:loss = 23.702711, step = 30500 (0.130 sec)\nINFO:tensorflow:global_step/sec: 841.326\nINFO:tensorflow:loss = 13.6766615, step = 30600 (0.118 sec)\nINFO:tensorflow:global_step/sec: 1023.97\nINFO:tensorflow:loss = 36.2195, step = 30700 (0.098 sec)\nINFO:tensorflow:global_step/sec: 1149.51\nINFO:tensorflow:loss = 14.072215, step = 30800 (0.086 sec)\nINFO:tensorflow:global_step/sec: 1096.25\nINFO:tensorflow:loss = 25.480919, step = 30900 (0.091 sec)\nINFO:tensorflow:global_step/sec: 1131.96\nINFO:tensorflow:loss = 25.239271, step = 31000 (0.089 sec)\nINFO:tensorflow:global_step/sec: 946.02\nINFO:tensorflow:loss = 16.598785, step = 31100 (0.106 sec)\nINFO:tensorflow:global_step/sec: 1039.97\nINFO:tensorflow:loss = 13.820374, step = 31200 (0.095 sec)\nINFO:tensorflow:global_step/sec: 869.776\nINFO:tensorflow:loss = 10.344806, step = 31300 (0.115 sec)\nINFO:tensorflow:global_step/sec: 1122.93\nINFO:tensorflow:loss = 7.0186515, step = 31400 (0.091 sec)\nINFO:tensorflow:global_step/sec: 1117.81\nINFO:tensorflow:loss = 13.343378, step = 31500 (0.087 sec)\nINFO:tensorflow:global_step/sec: 941.573\nINFO:tensorflow:loss = 42.582497, step = 31600 (0.106 sec)\nINFO:tensorflow:global_step/sec: 803.14\nINFO:tensorflow:loss = 9.63971, step = 31700 (0.127 sec)\nINFO:tensorflow:global_step/sec: 795.216\nINFO:tensorflow:loss = 12.116698, step = 31800 (0.124 sec)\nINFO:tensorflow:global_step/sec: 813.346\nINFO:tensorflow:loss = 19.307259, step = 31900 (0.124 sec)\nINFO:tensorflow:global_step/sec: 780.465\nINFO:tensorflow:loss = 3.6080003, step = 32000 (0.128 sec)\nINFO:tensorflow:global_step/sec: 725.336\nINFO:tensorflow:loss = 18.180222, step = 32100 (0.139 sec)\nINFO:tensorflow:global_step/sec: 727.786\nINFO:tensorflow:loss = 10.8895645, step = 32200 (0.136 sec)\nINFO:tensorflow:global_step/sec: 809.389\nINFO:tensorflow:loss = 4.709297, step = 32300 (0.123 sec)\nINFO:tensorflow:global_step/sec: 788.153\nINFO:tensorflow:loss = 11.608766, step = 32400 (0.128 sec)\nINFO:tensorflow:global_step/sec: 819.571\nINFO:tensorflow:loss = 19.3482, step = 32500 (0.122 sec)\nINFO:tensorflow:global_step/sec: 772.102\nINFO:tensorflow:loss = 10.591475, step = 32600 (0.130 sec)\nINFO:tensorflow:global_step/sec: 828.503\nINFO:tensorflow:loss = 7.0912085, step = 32700 (0.120 sec)\nINFO:tensorflow:global_step/sec: 615.099\nINFO:tensorflow:loss = 18.419651, step = 32800 (0.163 sec)\nINFO:tensorflow:global_step/sec: 750.125\nINFO:tensorflow:loss = 4.2064586, step = 32900 (0.134 sec)\nINFO:tensorflow:global_step/sec: 757.51\nINFO:tensorflow:loss = 10.868982, step = 33000 (0.131 sec)\nINFO:tensorflow:global_step/sec: 814.126\nINFO:tensorflow:loss = 15.584524, step = 33100 (0.124 sec)\nINFO:tensorflow:global_step/sec: 812.796\nINFO:tensorflow:loss = 13.895189, step = 33200 (0.124 sec)\nINFO:tensorflow:global_step/sec: 816.375\nINFO:tensorflow:loss = 13.999299, step = 33300 (0.121 sec)\nINFO:tensorflow:global_step/sec: 769.953\nINFO:tensorflow:loss = 20.122776, step = 33400 (0.129 sec)\nINFO:tensorflow:global_step/sec: 735.279\nINFO:tensorflow:loss = 17.09008, step = 33500 (0.137 sec)\nINFO:tensorflow:global_step/sec: 742.821\nINFO:tensorflow:loss = 13.75983, step = 33600 (0.135 sec)\nINFO:tensorflow:global_step/sec: 736.043\nINFO:tensorflow:loss = 15.056211, step = 33700 (0.136 sec)\nINFO:tensorflow:global_step/sec: 730.365\nINFO:tensorflow:loss = 14.744122, step = 33800 (0.138 sec)\nINFO:tensorflow:global_step/sec: 749.398\nINFO:tensorflow:loss = 17.642797, step = 33900 (0.135 sec)\nINFO:tensorflow:global_step/sec: 756.998\nINFO:tensorflow:loss = 10.547401, step = 34000 (0.129 sec)\nINFO:tensorflow:global_step/sec: 681.808\nINFO:tensorflow:loss = 20.303043, step = 34100 (0.149 sec)\nINFO:tensorflow:global_step/sec: 570.585\nINFO:tensorflow:loss = 6.8182693, step = 34200 (0.174 sec)\nINFO:tensorflow:global_step/sec: 587.948\nINFO:tensorflow:loss = 56.800148, step = 34300 (0.170 sec)\nINFO:tensorflow:global_step/sec: 555.341\nINFO:tensorflow:loss = 5.389482, step = 34400 (0.180 sec)\nINFO:tensorflow:global_step/sec: 583.699\nINFO:tensorflow:loss = 26.304594, step = 34500 (0.171 sec)\nINFO:tensorflow:global_step/sec: 708.268\nINFO:tensorflow:loss = 2.8505225, step = 34600 (0.142 sec)\nINFO:tensorflow:global_step/sec: 812.535\nINFO:tensorflow:loss = 6.342187, step = 34700 (0.121 sec)\nINFO:tensorflow:global_step/sec: 834.687\nINFO:tensorflow:loss = 10.489608, step = 34800 (0.120 sec)\nINFO:tensorflow:global_step/sec: 766.827\nINFO:tensorflow:loss = 25.085861, step = 34900 (0.130 sec)\nINFO:tensorflow:global_step/sec: 788.616\nINFO:tensorflow:loss = 9.008538, step = 35000 (0.129 sec)\nINFO:tensorflow:global_step/sec: 756.349\nINFO:tensorflow:loss = 3.8032315, step = 35100 (0.131 sec)\nINFO:tensorflow:global_step/sec: 833.228\nINFO:tensorflow:loss = 5.0383625, step = 35200 (0.119 sec)\nINFO:tensorflow:global_step/sec: 779.27\nINFO:tensorflow:loss = 15.505877, step = 35300 (0.128 sec)\nINFO:tensorflow:global_step/sec: 778.064\nINFO:tensorflow:loss = 10.112669, step = 35400 (0.129 sec)\nINFO:tensorflow:global_step/sec: 768.748\nINFO:tensorflow:loss = 14.012171, step = 35500 (0.130 sec)\nINFO:tensorflow:global_step/sec: 751.085\nINFO:tensorflow:loss = 27.887983, step = 35600 (0.133 sec)\nINFO:tensorflow:global_step/sec: 725.148\nINFO:tensorflow:loss = 11.370291, step = 35700 (0.137 sec)\nINFO:tensorflow:global_step/sec: 720.528\nINFO:tensorflow:loss = 7.4128757, step = 35800 (0.142 sec)\nINFO:tensorflow:global_step/sec: 728.699\nINFO:tensorflow:loss = 7.507187, step = 35900 (0.135 sec)\nINFO:tensorflow:global_step/sec: 789.13\nINFO:tensorflow:loss = 17.784594, step = 36000 (0.127 sec)\nINFO:tensorflow:global_step/sec: 812.402\nINFO:tensorflow:loss = 32.651596, step = 36100 (0.124 sec)\nINFO:tensorflow:global_step/sec: 783.323\nINFO:tensorflow:loss = 10.891145, step = 36200 (0.127 sec)\nINFO:tensorflow:global_step/sec: 810.924\nINFO:tensorflow:loss = 15.684954, step = 36300 (0.122 sec)\nINFO:tensorflow:global_step/sec: 748.669\nINFO:tensorflow:loss = 4.385976, step = 36400 (0.134 sec)\nINFO:tensorflow:global_step/sec: 706.708\nINFO:tensorflow:loss = 11.171715, step = 36500 (0.143 sec)\nINFO:tensorflow:global_step/sec: 564.775\nINFO:tensorflow:loss = 18.273432, step = 36600 (0.177 sec)\nINFO:tensorflow:global_step/sec: 736.146\nINFO:tensorflow:loss = 46.967804, step = 36700 (0.135 sec)\nINFO:tensorflow:global_step/sec: 832.836\nINFO:tensorflow:loss = 22.717245, step = 36800 (0.121 sec)\nINFO:tensorflow:global_step/sec: 780.601\nINFO:tensorflow:loss = 19.541252, step = 36900 (0.128 sec)\nINFO:tensorflow:global_step/sec: 807.571\nINFO:tensorflow:loss = 5.2323675, step = 37000 (0.126 sec)\nINFO:tensorflow:global_step/sec: 756.54\nINFO:tensorflow:loss = 8.575747, step = 37100 (0.131 sec)\nINFO:tensorflow:global_step/sec: 713.589\nINFO:tensorflow:loss = 0.95455056, step = 37200 (0.139 sec)\nINFO:tensorflow:global_step/sec: 741.259\nINFO:tensorflow:loss = 17.478703, step = 37300 (0.135 sec)\nINFO:tensorflow:global_step/sec: 726.656\nINFO:tensorflow:loss = 8.142177, step = 37400 (0.138 sec)\nINFO:tensorflow:global_step/sec: 724.227\nINFO:tensorflow:loss = 13.288649, step = 37500 (0.140 sec)\nINFO:tensorflow:global_step/sec: 778.926\nINFO:tensorflow:loss = 45.38794, step = 37600 (0.125 sec)\nINFO:tensorflow:global_step/sec: 785.706\nINFO:tensorflow:loss = 28.407452, step = 37700 (0.128 sec)\nINFO:tensorflow:global_step/sec: 784.124\nINFO:tensorflow:loss = 5.3852935, step = 37800 (0.129 sec)\nINFO:tensorflow:global_step/sec: 724.022\nINFO:tensorflow:loss = 12.906355, step = 37900 (0.136 sec)\nINFO:tensorflow:global_step/sec: 769.784\nINFO:tensorflow:loss = 12.262215, step = 38000 (0.133 sec)\nINFO:tensorflow:global_step/sec: 570.803\nINFO:tensorflow:loss = 30.330687, step = 38100 (0.172 sec)\nINFO:tensorflow:global_step/sec: 788.609\nINFO:tensorflow:loss = 18.953665, step = 38200 (0.128 sec)\nINFO:tensorflow:global_step/sec: 818.679\nINFO:tensorflow:loss = 11.944342, step = 38300 (0.121 sec)\nINFO:tensorflow:global_step/sec: 620.619\nINFO:tensorflow:loss = 17.596233, step = 38400 (0.163 sec)\nINFO:tensorflow:global_step/sec: 569.355\nINFO:tensorflow:loss = 20.67572, step = 38500 (0.175 sec)\nINFO:tensorflow:global_step/sec: 533.462\nINFO:tensorflow:loss = 12.247645, step = 38600 (0.188 sec)\nINFO:tensorflow:global_step/sec: 504.581\nINFO:tensorflow:loss = 29.36073, step = 38700 (0.198 sec)\nINFO:tensorflow:global_step/sec: 475.122\nINFO:tensorflow:loss = 41.846962, step = 38800 (0.209 sec)\nINFO:tensorflow:global_step/sec: 641.539\nINFO:tensorflow:loss = 14.657551, step = 38900 (0.157 sec)\nINFO:tensorflow:global_step/sec: 752.258\nINFO:tensorflow:loss = 11.647725, step = 39000 (0.132 sec)\nINFO:tensorflow:global_step/sec: 599.112\nINFO:tensorflow:loss = 6.7578917, step = 39100 (0.172 sec)\nINFO:tensorflow:global_step/sec: 666.02\nINFO:tensorflow:loss = 6.573803, step = 39200 (0.146 sec)\nINFO:tensorflow:global_step/sec: 765.075\nINFO:tensorflow:loss = 22.807682, step = 39300 (0.130 sec)\nINFO:tensorflow:global_step/sec: 670.536\nINFO:tensorflow:loss = 7.6244497, step = 39400 (0.149 sec)\nINFO:tensorflow:global_step/sec: 749.667\nINFO:tensorflow:loss = 3.6055217, step = 39500 (0.133 sec)\nINFO:tensorflow:global_step/sec: 752.61\nINFO:tensorflow:loss = 9.413443, step = 39600 (0.133 sec)\nINFO:tensorflow:global_step/sec: 764.137\nINFO:tensorflow:loss = 15.5864935, step = 39700 (0.132 sec)\nINFO:tensorflow:global_step/sec: 749.969\nINFO:tensorflow:loss = 10.392685, step = 39800 (0.133 sec)\nINFO:tensorflow:global_step/sec: 665.225\nINFO:tensorflow:loss = 9.498969, step = 39900 (0.149 sec)\nINFO:tensorflow:Saving checkpoints for 40000 into models/autompg-dnnregressor/model.ckpt.\nINFO:tensorflow:Loss for final step: 6.573916.\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tensorflow_estimator.python.estimator.canned.dnn.DNNRegressorV2 at 0x1ceb4020c48>"
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "EPOCHS = 1000\n",
    "BATCH_SIZE = 8\n",
    "total_steps = EPOCHS * int(np.ceil(len(df_train) / BATCH_SIZE))\n",
    "print('Training Steps:', total_steps)\n",
    "\n",
    "regressor.train(\n",
    "    input_fn=lambda:train_input_fn(df_train_norm, batch_size=BATCH_SIZE),\n",
    "    steps=total_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Reloading the last checkpoint\n",
    "- Calling .train() will automatically save the checkpoints during the training of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "INFO:tensorflow:Using default config.\nINFO:tensorflow:Using config: {'_model_dir': 'models/autompg-dnnregressor/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\ngraph_options {\n  rewrite_options {\n    meta_optimizer_iterations: ONE\n  }\n}\n, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000001CEB4CD9988>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
    }
   ],
   "source": [
    "reloaded_regressor = tf.estimator.DNNRegressor(\n",
    "    feature_columns=all_feature_columns,\n",
    "    hidden_units=[32, 10],\n",
    "    warm_start_from='models/autompg-dnnregressor/',\n",
    "    model_dir='models/autompg-dnnregressor/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3. Evaluate the predictive performance of the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "INFO:tensorflow:Calling model_fn.\nWARNING:tensorflow:Layer dnn is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n\nIf you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n\nTo change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n\nINFO:tensorflow:Done calling model_fn.\nINFO:tensorflow:Starting evaluation at 2020-07-26T23:10:08Z\nINFO:tensorflow:Graph was finalized.\nINFO:tensorflow:Restoring parameters from models/autompg-dnnregressor/model.ckpt-40000\nINFO:tensorflow:Running local_init_op.\nINFO:tensorflow:Done running local_init_op.\nINFO:tensorflow:Finished evaluation at 2020-07-26-23:10:08\nINFO:tensorflow:Saving dict for global step 40000: average_loss = 18.712437, global_step = 40000, label/mean = 23.611393, loss = 18.588703, prediction/mean = 21.755104\nINFO:tensorflow:Saving 'checkpoint_path' summary for global step 40000: models/autompg-dnnregressor/model.ckpt-40000\naverage_loss    18.71243667602539\nlabel/mean      23.611392974853516\nloss            18.588703155517578\nprediction/mean 21.755104064941406\nglobal_step     40000\nAverage-Loss 18.7124\n"
    }
   ],
   "source": [
    "def eval_input_fn(df_test, batch_size=8):\n",
    "    df = df_test.copy()\n",
    "    test_x, test_y = df, df.pop('MPG')\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((dict(test_x), test_y))\n",
    "\n",
    "    return dataset.batch(batch_size)\n",
    "\n",
    "eval_results = reloaded_regressor.evaluate(\n",
    "    input_fn=lambda:eval_input_fn(df_test_norm, batch_size=8))\n",
    "\n",
    "for key in eval_results:\n",
    "    print('{:15s} {}'.format(key, eval_results[key]))\n",
    "    \n",
    "print('Average-Loss {:.4f}'.format(eval_results['average_loss']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4. Predict the target values on new data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "INFO:tensorflow:Calling model_fn.\nWARNING:tensorflow:Layer dnn is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n\nIf you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n\nTo change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n\nINFO:tensorflow:Done calling model_fn.\nINFO:tensorflow:Graph was finalized.\nINFO:tensorflow:Restoring parameters from models/autompg-dnnregressor/model.ckpt-40000\nINFO:tensorflow:Running local_init_op.\nINFO:tensorflow:Done running local_init_op.\n{'predictions': array([22.291758], dtype=float32)}\n"
    }
   ],
   "source": [
    "pred_res = regressor.predict(input_fn=lambda: eval_input_fn(df_test_norm, batch_size=8))\n",
    "\n",
    "print(next(iter(pred_res)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5. Train a different pre-made Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "ensorflow:loss = 0.22530511, step = 5980 (0.218 sec)\nINFO:tensorflow:global_step/sec: 433.85\nINFO:tensorflow:loss = 0.09022692, step = 6080 (0.237 sec)\nINFO:tensorflow:global_step/sec: 421.444\nINFO:tensorflow:loss = 0.14605376, step = 6180 (0.238 sec)\nINFO:tensorflow:global_step/sec: 414.011\nINFO:tensorflow:loss = 0.08655515, step = 6280 (0.280 sec)\nINFO:tensorflow:global_step/sec: 362.307\nINFO:tensorflow:loss = 0.025377247, step = 6380 (0.278 sec)\nINFO:tensorflow:global_step/sec: 361.249\nINFO:tensorflow:loss = 0.05110468, step = 6480 (0.297 sec)\nINFO:tensorflow:global_step/sec: 342.469\nINFO:tensorflow:loss = 0.044005483, step = 6580 (0.218 sec)\nINFO:tensorflow:global_step/sec: 448.969\nINFO:tensorflow:loss = 0.15501904, step = 6680 (0.225 sec)\nINFO:tensorflow:global_step/sec: 451.42\nINFO:tensorflow:loss = 0.14872582, step = 6780 (0.228 sec)\nINFO:tensorflow:global_step/sec: 440.52\nINFO:tensorflow:loss = 0.05451867, step = 6880 (0.235 sec)\nINFO:tensorflow:global_step/sec: 417.3\nINFO:tensorflow:loss = 0.1471031, step = 6980 (0.249 sec)\nINFO:tensorflow:global_step/sec: 409.022\nINFO:tensorflow:loss = 0.15757614, step = 7080 (0.245 sec)\nINFO:tensorflow:global_step/sec: 408.675\nINFO:tensorflow:loss = 0.064261176, step = 7180 (0.237 sec)\nINFO:tensorflow:global_step/sec: 404.232\nINFO:tensorflow:loss = 0.07836231, step = 7280 (0.233 sec)\nINFO:tensorflow:global_step/sec: 426.226\nINFO:tensorflow:loss = 0.14597665, step = 7380 (0.253 sec)\nINFO:tensorflow:global_step/sec: 410.924\nINFO:tensorflow:loss = 0.1855281, step = 7480 (0.236 sec)\nINFO:tensorflow:global_step/sec: 424.287\nINFO:tensorflow:loss = 0.11733279, step = 7580 (0.245 sec)\nINFO:tensorflow:global_step/sec: 413.531\nINFO:tensorflow:loss = 0.062898465, step = 7680 (0.238 sec)\nINFO:tensorflow:global_step/sec: 409.527\nINFO:tensorflow:loss = 0.13691744, step = 7780 (0.248 sec)\nINFO:tensorflow:global_step/sec: 393.183\nINFO:tensorflow:loss = 0.10222931, step = 7880 (0.233 sec)\nINFO:tensorflow:global_step/sec: 438.077\nINFO:tensorflow:loss = 0.021404605, step = 7980 (0.246 sec)\nINFO:tensorflow:global_step/sec: 414.224\nINFO:tensorflow:loss = 0.07298987, step = 8080 (0.237 sec)\nINFO:tensorflow:global_step/sec: 422.493\nINFO:tensorflow:loss = 0.07611526, step = 8180 (0.278 sec)\nINFO:tensorflow:global_step/sec: 356.212\nINFO:tensorflow:loss = 0.15766737, step = 8280 (0.241 sec)\nINFO:tensorflow:global_step/sec: 422.426\nINFO:tensorflow:loss = 0.03561151, step = 8380 (0.239 sec)\nINFO:tensorflow:global_step/sec: 405.6\nINFO:tensorflow:loss = 0.106485814, step = 8480 (0.250 sec)\nINFO:tensorflow:global_step/sec: 406\nINFO:tensorflow:loss = 0.08312599, step = 8580 (0.268 sec)\nINFO:tensorflow:global_step/sec: 358.314\nINFO:tensorflow:loss = 0.014377295, step = 8680 (0.301 sec)\nINFO:tensorflow:global_step/sec: 332.421\nINFO:tensorflow:loss = 0.046900436, step = 8780 (0.326 sec)\nINFO:tensorflow:global_step/sec: 312.298\nINFO:tensorflow:loss = 0.030161886, step = 8880 (0.263 sec)\nINFO:tensorflow:global_step/sec: 380.519\nINFO:tensorflow:loss = 0.046785943, step = 8980 (0.249 sec)\nINFO:tensorflow:global_step/sec: 399.431\nINFO:tensorflow:loss = 0.100410566, step = 9080 (0.246 sec)\nINFO:tensorflow:global_step/sec: 413.118\nINFO:tensorflow:loss = 0.021130882, step = 9180 (0.247 sec)\nINFO:tensorflow:global_step/sec: 412.074\nINFO:tensorflow:loss = 0.004507992, step = 9280 (0.250 sec)\nINFO:tensorflow:global_step/sec: 389.922\nINFO:tensorflow:loss = 0.07294921, step = 9380 (0.311 sec)\nINFO:tensorflow:global_step/sec: 320.988\nINFO:tensorflow:loss = 0.060453944, step = 9480 (0.300 sec)\nINFO:tensorflow:global_step/sec: 339.891\nINFO:tensorflow:loss = 0.049772993, step = 9580 (0.235 sec)\nINFO:tensorflow:global_step/sec: 394.151\nINFO:tensorflow:loss = 0.016400993, step = 9680 (0.280 sec)\nINFO:tensorflow:global_step/sec: 375.152\nINFO:tensorflow:loss = 0.029260688, step = 9780 (0.261 sec)\nINFO:tensorflow:global_step/sec: 389.783\nINFO:tensorflow:loss = 0.08761872, step = 9880 (0.251 sec)\nINFO:tensorflow:global_step/sec: 393.517\nINFO:tensorflow:loss = 0.04599036, step = 9980 (0.297 sec)\nINFO:tensorflow:global_step/sec: 341.495\nINFO:tensorflow:loss = 0.038152937, step = 10080 (0.260 sec)\nINFO:tensorflow:global_step/sec: 377.576\nINFO:tensorflow:loss = 0.019627888, step = 10180 (0.264 sec)\nINFO:tensorflow:global_step/sec: 362.892\nINFO:tensorflow:loss = 0.026231319, step = 10280 (0.269 sec)\nINFO:tensorflow:global_step/sec: 385.31\nINFO:tensorflow:loss = 0.008990489, step = 10380 (0.264 sec)\nINFO:tensorflow:global_step/sec: 374.969\nINFO:tensorflow:loss = 0.023389827, step = 10480 (0.271 sec)\nINFO:tensorflow:global_step/sec: 382.686\nINFO:tensorflow:loss = 0.010671083, step = 10580 (0.251 sec)\nINFO:tensorflow:global_step/sec: 389.665\nINFO:tensorflow:loss = 0.030795451, step = 10680 (0.279 sec)\nINFO:tensorflow:global_step/sec: 368.916\nINFO:tensorflow:loss = 0.014185669, step = 10780 (0.289 sec)\nINFO:tensorflow:global_step/sec: 305.849\nINFO:tensorflow:loss = 0.01873409, step = 10880 (0.320 sec)\nINFO:tensorflow:global_step/sec: 322.542\nINFO:tensorflow:loss = 0.02415231, step = 10980 (0.321 sec)\nINFO:tensorflow:global_step/sec: 335.106\nINFO:tensorflow:loss = 0.014228402, step = 11080 (0.251 sec)\nINFO:tensorflow:global_step/sec: 397.746\nINFO:tensorflow:loss = 0.022622999, step = 11180 (0.265 sec)\nINFO:tensorflow:global_step/sec: 372.353\nINFO:tensorflow:loss = 0.020505978, step = 11280 (0.278 sec)\nINFO:tensorflow:global_step/sec: 363.658\nINFO:tensorflow:loss = 0.014137455, step = 11380 (0.262 sec)\nINFO:tensorflow:global_step/sec: 371.078\nINFO:tensorflow:loss = 0.010487109, step = 11480 (0.254 sec)\nINFO:tensorflow:global_step/sec: 392.948\nINFO:tensorflow:loss = 0.019161366, step = 11580 (0.276 sec)\nINFO:tensorflow:global_step/sec: 365.33\nINFO:tensorflow:loss = 0.01836086, step = 11680 (0.269 sec)\nINFO:tensorflow:global_step/sec: 379.929\nINFO:tensorflow:loss = 0.011439163, step = 11780 (0.276 sec)\nINFO:tensorflow:global_step/sec: 358.993\nINFO:tensorflow:loss = 0.024307376, step = 11880 (0.287 sec)\nINFO:tensorflow:global_step/sec: 341.199\nINFO:tensorflow:loss = 0.0043700924, step = 11980 (0.281 sec)\nINFO:tensorflow:global_step/sec: 349.243\nINFO:tensorflow:loss = 0.011032663, step = 12080 (0.269 sec)\nINFO:tensorflow:global_step/sec: 386.017\nINFO:tensorflow:loss = 0.04767792, step = 12180 (0.274 sec)\nINFO:tensorflow:global_step/sec: 367.345\nINFO:tensorflow:loss = 0.0025809628, step = 12280 (0.272 sec)\nINFO:tensorflow:global_step/sec: 366.198\nINFO:tensorflow:loss = 0.0246481, step = 12380 (0.271 sec)\nINFO:tensorflow:global_step/sec: 375.568\nINFO:tensorflow:loss = 0.0058383876, step = 12480 (0.268 sec)\nINFO:tensorflow:global_step/sec: 370.059\nINFO:tensorflow:loss = 0.0073810173, step = 12580 (0.256 sec)\nINFO:tensorflow:global_step/sec: 377.581\nINFO:tensorflow:loss = 0.009187583, step = 12680 (0.272 sec)\nINFO:tensorflow:global_step/sec: 361.512\nINFO:tensorflow:loss = 0.0024885905, step = 12780 (0.290 sec)\nINFO:tensorflow:global_step/sec: 358.507\nINFO:tensorflow:loss = 0.008003996, step = 12880 (0.316 sec)\nINFO:tensorflow:global_step/sec: 305.342\nINFO:tensorflow:loss = 0.0067604, step = 12980 (0.347 sec)\nINFO:tensorflow:global_step/sec: 281.288\nINFO:tensorflow:loss = 0.008707965, step = 13080 (0.320 sec)\nINFO:tensorflow:global_step/sec: 334.967\nINFO:tensorflow:loss = 0.004570877, step = 13180 (0.259 sec)\nINFO:tensorflow:global_step/sec: 367.682\nINFO:tensorflow:loss = 0.0130305765, step = 13280 (0.268 sec)\nINFO:tensorflow:global_step/sec: 372.737\nINFO:tensorflow:loss = 0.0077090627, step = 13380 (0.284 sec)\nINFO:tensorflow:global_step/sec: 369.416\nINFO:tensorflow:loss = 0.0056980727, step = 13480 (0.274 sec)\nINFO:tensorflow:global_step/sec: 361.655\nINFO:tensorflow:loss = 0.005654265, step = 13580 (0.283 sec)\nINFO:tensorflow:global_step/sec: 357.653\nINFO:tensorflow:loss = 0.003928752, step = 13680 (0.291 sec)\nINFO:tensorflow:global_step/sec: 335.253\nINFO:tensorflow:loss = 0.011130035, step = 13780 (0.281 sec)\nINFO:tensorflow:global_step/sec: 341.913\nINFO:tensorflow:loss = 0.007143939, step = 13880 (0.290 sec)\nINFO:tensorflow:global_step/sec: 363.532\nINFO:tensorflow:loss = 0.002262864, step = 13980 (0.286 sec)\nINFO:tensorflow:global_step/sec: 344.344\nINFO:tensorflow:loss = 0.0025564143, step = 14080 (0.286 sec)\nINFO:tensorflow:global_step/sec: 351.978\nINFO:tensorflow:loss = 0.0024677322, step = 14180 (0.286 sec)\nINFO:tensorflow:global_step/sec: 354.691\nINFO:tensorflow:loss = 0.004524367, step = 14280 (0.282 sec)\nINFO:tensorflow:global_step/sec: 354.758\nINFO:tensorflow:loss = 0.0014185549, step = 14380 (0.274 sec)\nINFO:tensorflow:global_step/sec: 346.91\nINFO:tensorflow:loss = 0.012042193, step = 14480 (0.286 sec)\nINFO:tensorflow:global_step/sec: 365.203\nINFO:tensorflow:loss = 0.005880945, step = 14580 (0.276 sec)\nINFO:tensorflow:global_step/sec: 361.013\nINFO:tensorflow:loss = 0.0035442673, step = 14680 (0.289 sec)\nINFO:tensorflow:global_step/sec: 348.611\nINFO:tensorflow:loss = 0.0035312965, step = 14780 (0.315 sec)\nINFO:tensorflow:global_step/sec: 314.059\nINFO:tensorflow:loss = 0.013488932, step = 14880 (0.339 sec)\nINFO:tensorflow:global_step/sec: 289.51\nINFO:tensorflow:loss = 0.005250057, step = 14980 (0.341 sec)\nINFO:tensorflow:global_step/sec: 274.185\nINFO:tensorflow:loss = 0.0042906627, step = 15080 (0.341 sec)\nINFO:tensorflow:global_step/sec: 312.901\nINFO:tensorflow:loss = 0.0011746073, step = 15180 (0.309 sec)\nINFO:tensorflow:global_step/sec: 335.573\nINFO:tensorflow:loss = 0.0030522048, step = 15280 (0.299 sec)\nINFO:tensorflow:global_step/sec: 334.844\nINFO:tensorflow:loss = 0.0034336974, step = 15380 (0.326 sec)\nINFO:tensorflow:global_step/sec: 301.111\nINFO:tensorflow:loss = 0.0030169564, step = 15480 (0.293 sec)\nINFO:tensorflow:global_step/sec: 349.445\nINFO:tensorflow:loss = 0.0024007987, step = 15580 (0.284 sec)\nINFO:tensorflow:global_step/sec: 332.798\nINFO:tensorflow:loss = 0.003933329, step = 15680 (0.280 sec)\nINFO:tensorflow:global_step/sec: 374.602\nINFO:tensorflow:loss = 0.003348451, step = 15780 (0.293 sec)\nINFO:tensorflow:global_step/sec: 334.952\nINFO:tensorflow:loss = 0.0027205653, step = 15880 (0.314 sec)\nINFO:tensorflow:global_step/sec: 323.733\nINFO:tensorflow:loss = 0.007594725, step = 15980 (0.300 sec)\nINFO:tensorflow:global_step/sec: 332.789\nINFO:tensorflow:loss = 0.00084045983, step = 16080 (0.313 sec)\nINFO:tensorflow:global_step/sec: 314.431\nINFO:tensorflow:loss = 0.0011455407, step = 16180 (0.307 sec)\nINFO:tensorflow:global_step/sec: 318.815\nINFO:tensorflow:loss = 0.0069277706, step = 16280 (0.305 sec)\nINFO:tensorflow:global_step/sec: 337.527\nINFO:tensorflow:loss = 0.0033260449, step = 16380 (0.301 sec)\nINFO:tensorflow:global_step/sec: 325.584\nINFO:tensorflow:loss = 0.0021696794, step = 16480 (0.321 sec)\nINFO:tensorflow:global_step/sec: 321.138\nINFO:tensorflow:loss = 0.002300907, step = 16580 (0.311 sec)\nINFO:tensorflow:global_step/sec: 324.191\nINFO:tensorflow:loss = 0.0034389026, step = 16680 (0.301 sec)\nINFO:tensorflow:global_step/sec: 322.512\nINFO:tensorflow:loss = 0.0017198921, step = 16780 (0.358 sec)\nINFO:tensorflow:global_step/sec: 264.92\nINFO:tensorflow:loss = 0.0035813102, step = 16880 (0.382 sec)\nINFO:tensorflow:global_step/sec: 270.43\nINFO:tensorflow:loss = 0.0017599592, step = 16980 (0.302 sec)\nINFO:tensorflow:global_step/sec: 339.818\nINFO:tensorflow:loss = 0.0027931938, step = 17080 (0.318 sec)\nINFO:tensorflow:global_step/sec: 322.933\nINFO:tensorflow:loss = 0.0027864436, step = 17180 (0.299 sec)\nINFO:tensorflow:global_step/sec: 329.522\nINFO:tensorflow:loss = 0.0016703457, step = 17280 (0.308 sec)\nINFO:tensorflow:global_step/sec: 331.415\nINFO:tensorflow:loss = 0.0014817968, step = 17380 (0.301 sec)\nINFO:tensorflow:global_step/sec: 308.342\nINFO:tensorflow:loss = 0.001449781, step = 17480 (0.313 sec)\nINFO:tensorflow:global_step/sec: 339.039\nINFO:tensorflow:loss = 0.00036243896, step = 17580 (0.305 sec)\nINFO:tensorflow:global_step/sec: 328.003\nINFO:tensorflow:loss = 0.002783819, step = 17680 (0.306 sec)\nINFO:tensorflow:global_step/sec: 315.605\nINFO:tensorflow:loss = 0.0027887174, step = 17780 (0.336 sec)\nINFO:tensorflow:global_step/sec: 310.325\nINFO:tensorflow:loss = 0.00041552336, step = 17880 (0.306 sec)\nINFO:tensorflow:global_step/sec: 323.475\nINFO:tensorflow:loss = 0.0008252658, step = 17980 (0.348 sec)\nINFO:tensorflow:global_step/sec: 274.089\nINFO:tensorflow:loss = 0.008508368, step = 18080 (0.319 sec)\nINFO:tensorflow:global_step/sec: 329.48\nINFO:tensorflow:loss = 0.0008136387, step = 18180 (0.332 sec)\nINFO:tensorflow:global_step/sec: 301.296\nINFO:tensorflow:loss = 0.0019404347, step = 18280 (0.316 sec)\nINFO:tensorflow:global_step/sec: 311.926\nINFO:tensorflow:loss = 0.00030423957, step = 18380 (0.346 sec)\nINFO:tensorflow:global_step/sec: 295.811\nINFO:tensorflow:loss = 0.00096077664, step = 18480 (0.304 sec)\nINFO:tensorflow:global_step/sec: 322.175\nINFO:tensorflow:loss = 0.00091656175, step = 18580 (0.364 sec)\nINFO:tensorflow:global_step/sec: 254.049\nINFO:tensorflow:loss = 0.0019283858, step = 18680 (0.417 sec)\nINFO:tensorflow:global_step/sec: 251.907\nINFO:tensorflow:loss = 0.0005280067, step = 18780 (0.332 sec)\nINFO:tensorflow:global_step/sec: 310.535\nINFO:tensorflow:loss = 0.0028674472, step = 18880 (0.329 sec)\nINFO:tensorflow:global_step/sec: 293.706\nINFO:tensorflow:loss = 0.00055427523, step = 18980 (0.332 sec)\nINFO:tensorflow:global_step/sec: 314.811\nINFO:tensorflow:loss = 0.000867928, step = 19080 (0.325 sec)\nINFO:tensorflow:global_step/sec: 307.559\nINFO:tensorflow:loss = 0.0009134325, step = 19180 (0.324 sec)\nINFO:tensorflow:global_step/sec: 291.488\nINFO:tensorflow:loss = 0.000648967, step = 19280 (0.333 sec)\nINFO:tensorflow:global_step/sec: 312.941\nINFO:tensorflow:loss = 0.0014718488, step = 19380 (0.318 sec)\nINFO:tensorflow:global_step/sec: 319.417\nINFO:tensorflow:loss = 0.001026168, step = 19480 (0.323 sec)\nINFO:tensorflow:global_step/sec: 305.145\nINFO:tensorflow:loss = 0.0021983245, step = 19580 (0.341 sec)\nINFO:tensorflow:global_step/sec: 297.375\nINFO:tensorflow:loss = 0.0014847799, step = 19680 (0.324 sec)\nINFO:tensorflow:global_step/sec: 310.631\nINFO:tensorflow:loss = 0.002126089, step = 19780 (0.309 sec)\nINFO:tensorflow:global_step/sec: 289.909\nINFO:tensorflow:loss = 0.00023746912, step = 19880 (0.364 sec)\nINFO:tensorflow:global_step/sec: 298.625\nINFO:tensorflow:loss = 0.0035094528, step = 19980 (0.333 sec)\nINFO:tensorflow:global_step/sec: 300.886\nINFO:tensorflow:loss = 0.00044050015, step = 20080 (0.331 sec)\nINFO:tensorflow:global_step/sec: 298.572\nINFO:tensorflow:loss = 0.000732542, step = 20180 (0.352 sec)\nINFO:tensorflow:global_step/sec: 290.846\nINFO:tensorflow:loss = 0.00040430133, step = 20280 (0.364 sec)\nINFO:tensorflow:global_step/sec: 249.11\nINFO:tensorflow:loss = 0.00026467512, step = 20380 (0.432 sec)\nINFO:tensorflow:global_step/sec: 234.224\nINFO:tensorflow:loss = 0.00062047236, step = 20480 (0.336 sec)\nINFO:tensorflow:global_step/sec: 327.47\nINFO:tensorflow:loss = 0.0007726742, step = 20580 (0.312 sec)\nINFO:tensorflow:global_step/sec: 322.861\nINFO:tensorflow:loss = 0.0006302367, step = 20680 (0.332 sec)\nINFO:tensorflow:global_step/sec: 293.699\nINFO:tensorflow:loss = 0.00071218563, step = 20780 (0.336 sec)\nINFO:tensorflow:global_step/sec: 307.375\nINFO:tensorflow:loss = 0.00033066462, step = 20880 (0.322 sec)\nINFO:tensorflow:global_step/sec: 310.403\nINFO:tensorflow:loss = 0.0008270155, step = 20980 (0.338 sec)\nINFO:tensorflow:global_step/sec: 272.928\nINFO:tensorflow:loss = 0.0008623055, step = 21080 (0.347 sec)\nINFO:tensorflow:global_step/sec: 303.444\nINFO:tensorflow:loss = 0.000645757, step = 21180 (0.330 sec)\nINFO:tensorflow:global_step/sec: 310.727\nINFO:tensorflow:loss = 0.00047080536, step = 21280 (0.341 sec)\nINFO:tensorflow:global_step/sec: 285.326\nINFO:tensorflow:loss = 0.00018706055, step = 21380 (0.345 sec)\nINFO:tensorflow:global_step/sec: 296.56\nINFO:tensorflow:loss = 0.0002863233, step = 21480 (0.340 sec)\nINFO:tensorflow:global_step/sec: 298.105\nINFO:tensorflow:loss = 0.001032088, step = 21580 (0.337 sec)\nINFO:tensorflow:global_step/sec: 275.653\nINFO:tensorflow:loss = 0.0001812894, step = 21680 (0.350 sec)\nINFO:tensorflow:global_step/sec: 302.265\nINFO:tensorflow:loss = 0.00053313596, step = 21780 (0.347 sec)\nINFO:tensorflow:global_step/sec: 288.829\nINFO:tensorflow:loss = 0.0007236629, step = 21880 (0.356 sec)\nINFO:tensorflow:global_step/sec: 275.955\nINFO:tensorflow:loss = 0.0002827693, step = 21980 (0.399 sec)\nINFO:tensorflow:global_step/sec: 244.882\nINFO:tensorflow:loss = 0.00034910956, step = 22080 (0.425 sec)\nINFO:tensorflow:global_step/sec: 240.2\nINFO:tensorflow:loss = 0.00034334668, step = 22180 (0.370 sec)\nINFO:tensorflow:global_step/sec: 264.03\nINFO:tensorflow:loss = 0.00062603154, step = 22280 (0.333 sec)\nINFO:tensorflow:global_step/sec: 312.535\nINFO:tensorflow:loss = 0.0007049949, step = 22380 (0.326 sec)\nINFO:tensorflow:global_step/sec: 298.317\nINFO:tensorflow:loss = 0.00023048671, step = 22480 (0.357 sec)\nINFO:tensorflow:global_step/sec: 276.321\nINFO:tensorflow:loss = 0.0004490887, step = 22580 (0.358 sec)\nINFO:tensorflow:global_step/sec: 294.718\nINFO:tensorflow:loss = 9.471927e-05, step = 22680 (0.344 sec)\nINFO:tensorflow:global_step/sec: 286.458\nINFO:tensorflow:loss = 0.0005793192, step = 22780 (0.353 sec)\nINFO:tensorflow:global_step/sec: 278.598\nINFO:tensorflow:loss = 8.9580004e-05, step = 22880 (0.334 sec)\nINFO:tensorflow:global_step/sec: 302.737\nINFO:tensorflow:loss = 0.00037696093, step = 22980 (0.341 sec)\nINFO:tensorflow:global_step/sec: 290.959\nINFO:tensorflow:loss = 0.00047386973, step = 23080 (0.370 sec)\nINFO:tensorflow:global_step/sec: 275.396\nINFO:tensorflow:loss = 8.058666e-05, step = 23180 (0.344 sec)\nINFO:tensorflow:global_step/sec: 293.27\nINFO:tensorflow:loss = 0.00025270248, step = 23280 (0.354 sec)\nINFO:tensorflow:global_step/sec: 274.127\nINFO:tensorflow:loss = 0.0002992493, step = 23380 (0.348 sec)\nINFO:tensorflow:global_step/sec: 286.904\nINFO:tensorflow:loss = 0.00016067503, step = 23480 (0.340 sec)\nINFO:tensorflow:global_step/sec: 299.5\nINFO:tensorflow:loss = 0.00012777928, step = 23580 (0.406 sec)\nINFO:tensorflow:global_step/sec: 233.897\nINFO:tensorflow:loss = 8.4180676e-05, step = 23680 (0.441 sec)\nINFO:tensorflow:global_step/sec: 230.831\nINFO:tensorflow:loss = 0.00012658424, step = 23780 (0.363 sec)\nINFO:tensorflow:global_step/sec: 284.243\nINFO:tensorflow:loss = 0.0001676543, step = 23880 (0.369 sec)\nINFO:tensorflow:global_step/sec: 254.389\nINFO:tensorflow:loss = 0.00015753855, step = 23980 (0.399 sec)\nINFO:tensorflow:global_step/sec: 257.915\nINFO:tensorflow:Saving checkpoints for 24000 into C:\\Users\\Yonsken\\AppData\\Local\\Temp\\tmps9662bns\\model.ckpt.\nWARNING:tensorflow:Issue encountered when serializing resources.\nType is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n'_Resource' object has no attribute 'name'\nINFO:tensorflow:Loss for final step: 0.00019682481.\nINFO:tensorflow:Calling model_fn.\nINFO:tensorflow:Done calling model_fn.\nINFO:tensorflow:Starting evaluation at 2020-07-26T23:20:47Z\nINFO:tensorflow:Graph was finalized.\nINFO:tensorflow:Restoring parameters from C:\\Users\\Yonsken\\AppData\\Local\\Temp\\tmps9662bns\\model.ckpt-24000\nINFO:tensorflow:Running local_init_op.\nINFO:tensorflow:Done running local_init_op.\nINFO:tensorflow:Finished evaluation at 2020-07-26-23:20:47\nINFO:tensorflow:Saving dict for global step 24000: average_loss = 13.495803, global_step = 24000, label/mean = 23.611393, loss = 13.411245, prediction/mean = 22.312155\nWARNING:tensorflow:Issue encountered when serializing resources.\nType is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n'_Resource' object has no attribute 'name'\nINFO:tensorflow:Saving 'checkpoint_path' summary for global step 24000: C:\\Users\\Yonsken\\AppData\\Local\\Temp\\tmps9662bns\\model.ckpt-24000\n{'average_loss': 13.495803, 'label/mean': 23.611393, 'loss': 13.411245, 'prediction/mean': 22.312155, 'global_step': 24000}\nAverage-Loss 13.4958\n"
    }
   ],
   "source": [
    "boosted_tree = tf.estimator.BoostedTreesRegressor(\n",
    "    feature_columns=all_feature_columns,\n",
    "    n_batches_per_layer=20,\n",
    "    n_trees=200)\n",
    "\n",
    "boosted_tree.train(\n",
    "    input_fn=lambda:train_input_fn(df_train_norm, batch_size=BATCH_SIZE))\n",
    "\n",
    "eval_results = boosted_tree.evaluate(\n",
    "    input_fn=lambda:eval_input_fn(df_test_norm, batch_size=8))\n",
    "\n",
    "print(eval_results)\n",
    "\n",
    "print('Average-Loss {:.4f}'.format(eval_results['average_loss']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}